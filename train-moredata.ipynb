{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import LinkNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch = 8\n",
    "lr = 1e-4\n",
    "model_path = './data/models/resnet34_test.pth'\n",
    "gamma = 0.35\n",
    "brightness = 2.0\n",
    "colors = 0.25\n",
    "bce_w = 0\n",
    "car_w = 1\n",
    "train_dirs = ['data/train/', 'data/dataset/', 'data/carla-capture-20180528/']\n",
    "val_dirs=['data/carla-capture-20181305/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "def img_size(image: np.ndarray):\n",
    "    return (image.shape[1], image.shape[0])\n",
    "\n",
    "def gauss_noise(img, sigma_squared):\n",
    "    w, h = img_size(img)\n",
    "    gauss = np.random.normal(-sigma_squared, sigma_squared, (h, w, 3))\n",
    "    gauss = gauss.reshape(h, w, 3)\n",
    "    print(gauss.max(), img.max())\n",
    "    img = img + gauss\n",
    "    return img.astype(np.uint8)\n",
    "\n",
    "class GaussNoise(object):\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        return gauss_noise(img, self.sigma)\n",
    "\n",
    "class AugmentColor(object):\n",
    "    def __init__(self, gamma, brightness, colors):\n",
    "        self.gamma = gamma\n",
    "        self.brightness = brightness\n",
    "        self.colors = colors\n",
    "\n",
    "    def __call__(self, img):\n",
    "        p = np.random.uniform(0, 1, 1)\n",
    "        if p > 0.5:\n",
    "            # randomly shift gamma\n",
    "            random_gamma = torch.from_numpy(np.random.uniform(1-self.gamma, 1+self.gamma, 1)).type(torch.cuda.FloatTensor)\n",
    "            img  = img  ** random_gamma\n",
    "\n",
    "        p = np.random.uniform(0, 1, 1)\n",
    "        if p > 0.5:\n",
    "            # randomly shift brightness\n",
    "            random_brightness =  torch.from_numpy(np.random.uniform(1/self.brightness, self.brightness, 1))\\\n",
    "                .type(torch.cuda.FloatTensor)\n",
    "            img  =  img * random_brightness\n",
    "\n",
    "        p = np.random.uniform(0, 1, 1)\n",
    "        if p > 0.5:\n",
    "            # randomly shift color\n",
    "            random_colors =  torch.from_numpy(np.random.uniform(1-self.colors, 1+self.colors, 3))\\\n",
    "                .type(torch.cuda.FloatTensor)\n",
    "            white = torch.ones([np.shape(img)[1], np.shape(img)[2]]).type(torch.cuda.FloatTensor)\n",
    "            color_image = torch.stack([white * random_colors[i] for i in range(3)], dim=0)\n",
    "            img  *= color_image\n",
    "\n",
    "        # saturate\n",
    "        img  = torch.clamp(img,  0, 1)\n",
    "        return img\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __init__(self):\n",
    "        self.transform = transforms.ToTensor()\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return self.transform(sample).type(torch.cuda.FloatTensor)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    #GaussNoise(10),\n",
    "    ToTensor(),\n",
    "    AugmentColor(gamma, brightness, colors)\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    #GaussNoise(10),\n",
    "    ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "\n",
    "class LyftDataset(Dataset):\n",
    "    def __init__(self, data_dir, img_transform=None, trg_transform=None, read=True):\n",
    "        img_dir = os.path.join(data_dir, \"CameraRGB\")\n",
    "        trg_dir = os.path.join(data_dir, \"CameraSeg\")\n",
    "        img_paths = sorted(os.listdir(img_dir))\n",
    "        trg_paths = sorted(os.listdir(trg_dir))\n",
    "        self.img_paths = [os.path.join(img_dir, path) for path in img_paths]\n",
    "        self.trg_paths = [os.path.join(trg_dir, path) for path in trg_paths]\n",
    "        if read: \n",
    "            self.imgs = [cv2.imread(path) for path in self.img_paths]\n",
    "            self.trgs = [self._fix_trg(cv2.imread(path)) for path in self.trg_paths]\n",
    "        self.img_transform = img_transform\n",
    "        self.trg_transform = trg_transform\n",
    "        self.read = read\n",
    "    \n",
    "    def _fix_trg(self, trg):\n",
    "        h, w, _ = trg.shape\n",
    "        mask = np.zeros((h+2, w+2, 1), dtype=np.uint8)\n",
    "        cv2.floodFill(trg, mask, (w//2, h-1), (0,0,0))\n",
    "        vehicles = (trg[:, :, 2]==10).astype(np.float)\n",
    "        road = (trg[:, :, 2]==6).astype(np.float)\n",
    "        road += (trg[:, :, 2]==7).astype(np.float)\n",
    "        bg = np.ones(vehicles.shape) - vehicles - road\n",
    "        return np.stack([bg, road, vehicles], axis=2)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.read:\n",
    "            return len(self.imgs)\n",
    "        else:\n",
    "            return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.read:\n",
    "            img = self.imgs[idx]\n",
    "            trg = self.trgs[idx]\n",
    "        else:\n",
    "            img = cv2.imread(self.img_paths[idx])\n",
    "            trg = self._fix_trg(cv2.imread(self.trg_paths[idx]))\n",
    "        if self.img_transform is not None:\n",
    "            img = self.img_transform(img)\n",
    "        if self.trg_transform is not None:\n",
    "            trg = self.trg_transform(trg)\n",
    "        return img, trg\n",
    "\n",
    "train_datasets = [LyftDataset(train_dir, train_transform, transforms.ToTensor(), False) for train_dir in train_dirs]\n",
    "train_dataset = ConcatDataset(train_datasets)\n",
    "print(\"Train imgs:\", train_dataset.__len__())\n",
    "val_datasets = [LyftDataset(val_dir, val_transform, transforms.ToTensor(), False) for val_dir in val_dirs]\n",
    "val_dataset = ConcatDataset(val_datasets)\n",
    "print(\"Train imgs:\", val_dataset.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img, trg = train_dataset.__getitem__(80)\n",
    "def show_img(img):\n",
    "    plt.figure(dpi=300)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    for data in train_dataset:\n",
    "        print(data[0].shape, data[1].shape)\n",
    "        show_img(np.moveaxis(data[0].cpu().numpy(), 0, -1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import LyftLoss\n",
    "import torch.optim as optim\n",
    "train_loss = LyftLoss(bce_w=0, car_w=2, other_w=0.5).to(device)\n",
    "val_loss = LyftLoss(bce_w=0, car_w=1, other_w=0).to(device)\n",
    "model = LinkNet34(3, 3).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model_path = './data/models/resnet34_007_cpt1.pth'\n",
    "state = torch.load(load_model_path)\n",
    "model.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.synchronize()\n",
    "\n",
    "def val():\n",
    "    c_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for img, trg in val_loader:\n",
    "            img = img.type(torch.cuda.FloatTensor)\n",
    "            trg = trg.type(torch.cuda.FloatTensor)\n",
    "            pred = model(img)\n",
    "            loss = val_loss(pred, trg)\n",
    "            c_loss += loss.item()\n",
    "        c_loss /= val_dataset.__len__()\n",
    "    return c_loss\n",
    "\n",
    "losses = []\n",
    "best_loss = val()\n",
    "print(\"Start val loss:\", best_loss)\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    s_time = time.time()\n",
    "    for img, trg in train_loader:\n",
    "        # get the inputs\n",
    "        img = img.type(torch.cuda.FloatTensor)\n",
    "        trg = trg.type(torch.cuda.FloatTensor)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        pred = model(img)\n",
    "        loss = train_loss(pred, trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    running_loss /= train_dataset.__len__()\n",
    "    val = val()\n",
    "    print(\"Epoch:\", epoch+1, \"train loss:\", running_loss, \"val loss:\", val,\n",
    "          \"time:\", time.time()-s_time, \"s\")\n",
    "    if val < best_loss:\n",
    "        torch.save(model.state_dict(), model_path[:-4]+'_cpt'+model_path[-4:])\n",
    "        best_loss = val\n",
    "        print(\"Checkpoint saved\")\n",
    "    losses.append([running_loss, val])\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pred(fname):\n",
    "    img_test = cv2.imread(fname)\n",
    "    show_img(img_test)\n",
    "    img_test = np.moveaxis(img_test, -1, 0)\n",
    "    img_test = img_test[np.newaxis,:,:,:]\n",
    "    img_test = torch.from_numpy(img_test).type(torch.cuda.FloatTensor)\n",
    "    pred = model(img_test)\n",
    "    pred = pred.cpu().data[0,:,:,:].numpy()\n",
    "    pred_img = np.moveaxis(pred, 0, -1)\n",
    "    show_img(pred_img)\n",
    "    return pred_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = 473\n",
    "\n",
    "pred_img = show_pred('./data/train/CameraRGB/'+str(idx)+'.png')\n",
    "trg_test = train_datasets[0]._fix_trg(cv2.imread('./data/train/CameraSeg/'+str(idx)+'.png'))\n",
    "show_img(trg_test)\n",
    "show_img(np.abs(trg_test-pred_img[4:604,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "img_test = cv2.imread('./data/CameraRGB/'+str(idx)+'.png')\n",
    "img_test = np.moveaxis(img_test, -1, 0)\n",
    "img_test = img_test[np.newaxis,:,:,:]\n",
    "img_test = torch.from_numpy(img_test).type(torch.cuda.FloatTensor)\n",
    "pred = model(img_test)\n",
    "pred = pred.cpu().data[0,:,:,:].numpy()\n",
    "pred_img = np.moveaxis(pred, 0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
